from langchain_openai import ChatOpenAI

class GenerationAgent:
    def __init__(self, model_name="gpt-3.5-turbo"):
        self.llm = ChatOpenAI(model_name=model_name, temperature=0)

    def answer(self, question, docs, evaluation_agent, max_attempts=3):
        """
        ç”Ÿæˆç­”æ¡ˆï¼Œå¹¶ç»“åˆâ€œåˆ†æŒ‡æ ‡è¯„ä¼°â€ (Faithfulness, Response Relevancy, Noise Sensitivityç­‰)ã€‚
        è‹¥è´¨é‡ä¸è¶³ï¼Œä¼˜åŒ– Prompt å¹¶é‡æ–°ç”Ÿæˆã€‚
        """
        # å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£æ‹¼æˆæ–‡æœ¬
        context = "\n".join([f"<Document {i}> {doc.page_content}" for i, doc in enumerate(docs, start=1)])

        attempts = 0
        best_answer = ""
        best_score = 0.0  # å¦‚æœä½ æƒ³ç”¨ faithfulness åšè¡¡é‡ï¼Œä¹Ÿå¯ä½¿ç”¨ç»¼åˆåˆ†

        while attempts < max_attempts:
            prompt = f"""
            You are an AI assistant that answers questions based strictly on retrieved documents.
            Follow this structured reasoning process:

            Step 1: Extract the key facts from the retrieved context.
            Step 2: Summarize the main points that directly answer the question.
            Step 3: Generate the final answer strictly based on these extracted points.

            Question: {question}
            Retrieved Context:

            {context}

            Strictly based on the retrieved context above, provide the most accurate and faithful answer.
            If the context does not contain enough information, state that explicitly.
            """
            # 1) è°ƒç”¨ LLM ç”Ÿæˆå›ç­”
            raw_answer = self.llm.invoke(prompt)
            answer_text = raw_answer.content if hasattr(raw_answer, 'content') else str(raw_answer)

            # 2) ä½¿ç”¨â€œåˆ†æŒ‡æ ‡è¯„ä¼°â€ evaluate_generation
            #    (å¦‚æœä½ åªæƒ³è¦faithfulness, ä¹Ÿå¯åœ¨EvaluationAgenté‡Œåªè¯„ä¼°faithfulness)
            eval_result = evaluation_agent.evaluate_generation(
                user_query=question,
                retrieved_docs=docs,
                response=answer_text
            )

            # 3) è§£æåˆ†æ•°
            faithfulness_score = eval_result.get("faithfulness", 0.0)
            relevancy_score = eval_result.get("response_relevancy", 0.0)
            noise_sensitivity = eval_result.get("noise_sensitivity", 1.0)  # å‡è®¾é»˜è®¤=1 ä»£è¡¨å™ªéŸ³é«˜

            print(f"ğŸ” Attempt #{attempts+1}")
            print(f"   Faithfulness: {faithfulness_score:.2f}")
            print(f"   Relevancy: {relevancy_score:.2f}")
            print(f"   NoiseSensitivity: {noise_sensitivity:.2f}")

            # 4) è®¾å®šå¤šç»´é˜ˆå€¼ (æ ¹æ®éœ€æ±‚çµæ´»è°ƒæ•´)
            if faithfulness_score >= 0.6 and relevancy_score >= 0.5 and noise_sensitivity <= 0.4:
                print("âœ… Generation quality is sufficient. Returning answer.")
                return {
                    "answer": answer_text,
                    "faithfulness_score": faithfulness_score,
                    "response_relevancy": relevancy_score,
                    "noise_sensitivity": noise_sensitivity,
                }

            # å¦‚æœå½“å‰å¾—åˆ†æ¯”ä¹‹å‰æœ€å¥½æ›´é«˜ï¼Œå°±æ›´æ–°best_answer
            if faithfulness_score > best_score:
                best_answer = answer_text
                best_score = faithfulness_score

            # ä¸è¾¾æ ‡ â†’ å¯ä»¥è¿›è¡Œä¸€äº› Prompt æ”¹å†™ æˆ– Retry
            print("âš ï¸ Generation quality insufficient. Refining prompt and retrying...\n")
            attempts += 1

        print("âš ï¸ Max attempts reached, returning best available answer.")
        return {
            "answer": best_answer if best_answer else answer_text,
            "faithfulness_score": faithfulness_score,
            "response_relevancy": relevancy_score,
            "noise_sensitivity": noise_sensitivity,
        }
