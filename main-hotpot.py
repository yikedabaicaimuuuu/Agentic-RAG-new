from agents.reasoning_agent import ReasoningAgent
from agents.retrieval_agent import RetrievalAgent
from agents.evaluation_agent import EvaluationAgent
from agents.generation_agent import GenerationAgent
from agents.langgraph_rag import run_rag_pipeline

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
import dspy
from dspy.evaluate import SemanticF1
from tqdm import tqdm
import httpx
from langchain_openai import ChatOpenAI
import atexit

def main():

    # ------------------------
    # (1) åˆå§‹åŒ– DSPy LLM
    # ------------------------
    lm = dspy.LM('openai/gpt-3.5-turbo')
    dspy.configure(lm=lm)

    # ------------------------
    # (2) åˆå§‹åŒ– Embeddings & FAISS
    # ------------------------
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
    vectorstore_path = "vectorstore-hotpot/hotpotqa_faiss"
    vectorstore = FAISS.load_local(
        vectorstore_path,
        embeddings,
        allow_dangerous_deserialization=True
    )

    # ------------------------
    # (3) åˆå§‹åŒ–å„ Agent
    # ------------------------
    # ç”±äº ReasoningAgent ä¸å†éœ€è¦evaluation_agentæ¥è¯„ä¼°æœ€ç»ˆå›ç­”, å»æ‰å…¶æ„é€ å‚æ•°
    reasoning_agent = ReasoningAgent(model_name="gpt-3.5-turbo")
    # RetrieverAgent å¯ä¾æ—§ä¿ç•™evaluation_agentç”¨æ¥å†…éƒ¨è¯„ä¼°(å¯é€‰)
    evaluation_agent = EvaluationAgent(model_name="gpt-3.5-turbo")
    retrieval_agent = RetrievalAgent(
        vectorstore=vectorstore,
        evaluation_agent=evaluation_agent,  # è‹¥ä¸éœ€è¦ä¹Ÿå¯ä¼  None
        top_k=3
    )
    generation_agent = GenerationAgent(model_name="gpt-3.5-turbo")

    # ------------------------
    # (4) æµ‹è¯•é›†å¾ªç¯
    # ------------------------
    # å¦‚æœ ReasoningAgent å†…éƒ¨ç”¨ DSPy æœ‰ trainset/valset/testset,
    # å¯ä»¥å– reason_agent.testsetåšç®€å•æµ‹è¯•
    # å‡è®¾ reason_agent ä»åŠ è½½äº† dataset, å– 5 ä¸ªæµ‹è¯•æ ·æœ¬
    TESTSET_SIZE = 2
    total = min(TESTSET_SIZE, len(reasoning_agent.testset))
    subset_testset = reasoning_agent.testset[:total]

    print("\nğŸ§ª è¿è¡Œæµ‹è¯•é›†è¯„ä¼°...")
    correct = 0
    faithfulness_scores = []
    failed_cases = []

    # ç”¨ DSPy çš„ SemanticF1 è®¡ç®—å›ç­”ä¸groundtruthç›¸ä¼¼åº¦
    semantic_f1_metric = SemanticF1(decompositional=True)

    for i, example in enumerate(tqdm(subset_testset, desc="è¯„ä¼°æµ‹è¯•é›†")):
        question = example.question
        ground_truth = example.response
        print(f"\nğŸ” è¿è¡Œæµ‹è¯• {i+1}/{total} - é—®é¢˜: {question}")

        # (a) è°ƒç”¨æ–°çš„ RAG Pipeline
        result = run_rag_pipeline(
            question=question,
            retrieval_agent=retrieval_agent,
            reasoning_agent=reasoning_agent,
            generation_agent=generation_agent,
            evaluation_agent=evaluation_agent,
            reference=example.context  # âœ… ä¼ å…¥ ground truth ç”¨äº Recall è¯„ä¼°
        )

        # (b) è·å–å›ç­”å’ŒæŒ‡æ ‡ï¼ˆåŠ ä¸Šé»˜è®¤å€¼ä¿æŠ¤ï¼‰
        predicted_answer = result.get("answer", "")
        faithfulness_score = result.get("faithfulness_score", 0.0)
        relevancy_score = result.get("answer_relevancy", 0.0)
        noise_score = result.get("noise_sensitivity", 1.0)
        # ä¹Ÿå¯æ‹¿ response_relevancy, noise_sensitivity if needed

        # (c) è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
        similarity_score = semantic_f1_metric(example, dspy.Example(response=predicted_answer))
        faithfulness_scores.append(faithfulness_score)

        # åˆ¤æ–­æ˜¯å¦æ­£ç¡® (arbitrary threshold)
        if similarity_score > 0.7:
            correct += 1
        else:
            failed_cases.append({
                "question": question,
                "ground_truth": ground_truth,
                "predicted_answer": predicted_answer,
                "faithfulness_score": faithfulness_score,
                "relevancy_score": relevancy_score,
                "noise_score": noise_score,
                "similarity_score": similarity_score
            })

    # è®¡ç®—æµ‹è¯•å‡†ç¡®ç‡ & å¹³å‡å¿ å®åº¦
    avg_faithfulness = sum(faithfulness_scores) / len(faithfulness_scores) if faithfulness_scores else 0
    accuracy = correct / total * 100 if total > 0 else 0

    print(f"\nâœ… æµ‹è¯•å‡†ç¡®ç‡: {correct}/{total} ({accuracy:.2f}%)")
    print(f"ğŸ“Š å¹³å‡å¿ å®åº¦è¯„åˆ†: {avg_faithfulness:.2f}")

    # è¾“å‡ºå¤±è´¥æ¡ˆä¾‹
    if failed_cases:
        print("\nâš ï¸ å¤±è´¥æ¡ˆä¾‹ (ä½å¿ å®åº¦æˆ–ä½ç›¸ä¼¼åº¦):")
        for case in failed_cases[:5]:  # ä»…æ‰“å°å‰5ä¸ª
            print("\nğŸ” é—®é¢˜:", case["question"])
            print("ğŸ“– æ ‡å‡†ç­”æ¡ˆ:", case["ground_truth"])
            print("ğŸ“ é¢„æµ‹ç­”æ¡ˆ:", case["predicted_answer"])
            print(f"ğŸ“Š å¿ å®åº¦: {case['faithfulness_score']:.2f}")
            print(f"ğŸ¯ ç›¸å…³åº¦: {case['relevancy_score']:.2f}")
            print(f"ğŸ”Š å™ªéŸ³æ•æ„Ÿåº¦: {case['noise_score']:.2f}")
            print(f"âœ… è¯­ä¹‰ç›¸ä¼¼åº¦: {case['similarity_score']:.2f}")

if __name__ == "__main__":
    main()

