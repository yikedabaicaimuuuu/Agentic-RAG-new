import dspy
import json
import random
from langchain_openai import ChatOpenAI
import httpx


def load_dataset(json_path="data-hotpot/hotpot_mini_corpus.json", train_ratio=0.7, val_ratio=0.2):
    """åŠ è½½ Hotpot mini corpus (json) å¹¶æ‹†åˆ† trainset, valset, testset"""

    # åŠ è½½ JSON æ–‡ä»¶
    with open(json_path, 'r') as f:
        corpus = json.load(f)

    # **ç¡®ä¿æ•°æ®è¶³å¤Ÿå¤§**
    if len(corpus) < 10:
        raise ValueError("âš ï¸ æ•°æ®é‡å¤ªå°‘ï¼Œæ— æ³•è®­ç»ƒ MIPROv2ï¼è¯·å¢åŠ æ•°æ®ï¼")

    # **ç”Ÿæˆpseudo questions and answers**
    examples = []
    for item in corpus:
        # ğŸ”¥ ç°åœ¨ context æ˜¯å·²ç»æ¸…æ´—å¥½çš„é•¿æ–‡æœ¬
        context_text = item['context']
        question = item['question']
        answer = item['answer']

        examples.append(
            dspy.Example(context=context_text, question=question, response=answer).with_inputs("context", "question")
        )

    # **éšæœºæ‰“ä¹±æ•°æ®**
    random.shuffle(examples)

    # **è®¡ç®—æ•°æ®é›†å¤§å°**
    total_size = len(examples)
    train_size = int(total_size * train_ratio)
    val_size = int(total_size * val_ratio)
    test_size = total_size - train_size - val_size

    # **æ‹†åˆ†æ•°æ®**
    trainset, valset, testset = (
        examples[:train_size],
        examples[train_size:train_size+val_size],
        examples[train_size+val_size:]
    )

    # **ç¡®ä¿trainset/valsetä¸ä¸ºç©º**
    if not trainset or not valset:
        raise ValueError("âš ï¸ trainset æˆ– valset ä¸ºç©ºï¼Œæ— æ³•è¿è¡Œ MIPROv2ï¼Œè¯·æ£€æŸ¥æ•°æ®ï¼")

    return trainset, valset, testset


class ReasoningAgent:
    """
    ä»…æ‰§è¡Œ Query/Prompt ä¼˜åŒ–ï¼Œä¸ç›´æ¥è¯„ä¼°æœ€ç»ˆå›ç­”è´¨é‡ï¼Œä¹Ÿä¸äº§å‡ºæœ€ç»ˆå›ç­”ï¼›
    è€Œæ˜¯è¿”å› refined_queryï¼Œä¾› RetrievalAgent æˆ–åç»­ç¯èŠ‚è°ƒç”¨ã€‚
    """

    def __init__(self, model_name="gpt-3.5-turbo", llm=None):
        if llm is not None:
            self.llm = llm
        else:
            self.llm = ChatOpenAI(model_name=model_name, temperature=0)

        # â¶ ChainOfThoughtç­¾åå¿…é¡»æ˜¯ç®€å•æ ¼å¼
        self.chain = dspy.ChainOfThought("context, question -> response")

        # â· MIPROv2 ä¼˜åŒ–å™¨
        self.optimizer = dspy.MIPROv2(
            metric=dspy.evaluate.SemanticF1(),  # ç”¨SemanticF1è¯„ä¼°promptä¼˜åŒ–æ•ˆæœ
            auto="medium",
            num_threads=5
        )

        # â¸ åŠ è½½æ•°æ®é›†
        self.trainset, self.valset, self.testset = load_dataset(val_ratio=0.1)

         # â¹ ç¼–è¯‘ optimized agent (å¿…é¡»åœ¨æœ‰äº† trainset/valset å)
        self.optimized_agent = self.optimizer.compile(
            self.chain,
            trainset=self.trainset,
            valset=self.valset,
            requires_permission_to_run=False
        )

    def _should_fallback(self, retrieved_context: str) -> bool:
        """åˆ¤æ–­retrieved_contextæ˜¯å¦å¤ªå·®ï¼Œéœ€è¦fallback"""
        if len(retrieved_context.split()) < 50:
            return True
        keywords = ["overview", "history", "general", "unrelated", "background", "miscellaneous"]
        return any(kw.lower() in retrieved_context.lower() for kw in keywords)

    def _fewshot_examples(self) -> str:
        """æä¾› few-shot ç¤ºä¾‹"""
        return (
            "Example 1:\n"
            "Question: What are the main types of cloud computing?\n"
            "Retrieved docs: Discusses types of databases, benefits of cloud, and a small mention of SaaS.\n"
            "Refined query: Main categories of cloud computing services: IaaS, PaaS, and SaaS.\n\n"
            "Example 2:\n"
            "Question: How does photosynthesis work in plants?\n"
            "Retrieved docs: Talks about plant biology in general, mentions light and chlorophyll briefly.\n"
            "Refined query: Explain the stages of photosynthesis in plants, focusing on light-dependent and light-independent reactions.\n\n"
        )

    def _instruction_prefix(self) -> str:
        """ç”Ÿæˆä¼˜åŒ– refined_query æ—¶éœ€è¦çš„ instruction"""
        return (
            "Given the retrieved context and the user question:\n"
            "1. Analyze whether the retrieved context is sufficient, overly broad, noisy, or off-topic.\n"
            "2. If the context contains irrelevant information or lacks key details, refine the query to be more specific, targeted, and avoid irrelevant topics.\n"
            "3. Your goal is to produce a new query that maximizes precision without sacrificing necessary recall.\n"
            "4. If the context is empty or irrelevant, generate a completely new, highly focused query based on the question itself.\n\n"
        )

    def plan(self, user_question, retrieved_docs=None):
        """æ ¸å¿ƒæ–¹æ³•ï¼šç”Ÿæˆ refined_queryï¼ŒåŒæ—¶æ”¯æŒåŠ¨æ€fallbackå’Œfew-shotå¼•å¯¼"""

        retrieved_context = ""
        fallback = False

        if retrieved_docs:
            retrieved_context = "\n".join(doc.page_content for doc in retrieved_docs)

            if self._should_fallback(retrieved_context):
                print("âš ï¸ æ£€æµ‹åˆ°retrieved contextè´¨é‡å·®ï¼Œç›´æ¥fallbackåˆ° user_question")
                fallback = True
            else:
                print("âœ… Retrieved contextè´¨é‡è‰¯å¥½ï¼Œæ­£å¸¸ä¼˜åŒ– refined_query")
                # åŠ  few-shot + æŒ‡ä»¤å¼•å¯¼
                few_shot_context = self._fewshot_examples()
                instruction = self._instruction_prefix()
                retrieved_context = instruction + few_shot_context + "====\n" + retrieved_context
        else:
            print("âš ï¸ æ²¡æœ‰retrieved docsï¼Œç›´æ¥ä½¿ç”¨ user_question")
            fallback = True

        if fallback:
            # fallbackæ—¶åªç”¨instruction + user_question
            dspy_response = self.optimized_agent(context=self._instruction_prefix(), question=user_question)
        else:
            dspy_response = self.optimized_agent(context=retrieved_context, question=user_question)

        if hasattr(dspy_response, "response"):
            refined_query = dspy_response.response
        else:
            refined_query = str(dspy_response)

        return {
            "refined_query": refined_query
        }


